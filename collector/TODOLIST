Универсальность сделать слишком трудоемко т.к., даже если реализовать динамическое создание таблиц для приема данных,
то для составления отчетов на основе этих данных нужно динамически генерировать SQL-запросы для их получения, вкупе с
индексированием.

В этой версии нужно: 

1. Захардкодить прием данных только по шаблонам cs_req и cs_resp.
 - убрать внутренний буфер
 - писать данные сразу в БД, таблицы секционировать по датам.
 - создание новых и удаление старых секций производить автоматически с помощью pg_agent
 - ввести параметр истории хранения

3. Реализовать правильную остановку приложения

4. Реализовать получение данных о статусе коллектора через api

5. Реализовать ввод шаблонов из XML-файла.


Логика работы коллектора.

Все полученные записи пишутся в секцию текущего дня (созданную заранее для каждого экспортируемого шаблона), например:

cs_req_YYYYMMDD
cs_resp_YYYYMMDD
generic_YYYYMMDD

Каждую ночь нужно для каждого типа, текущая дата = day:

1. Создать новую секцию, т.е. для завтрашнего дня: day + 1 (быстрая операция)
2. Отсоединить вчерашнюю секцию от основной таблицы: day - 1 (быстрая операция)
3. Создать во вчерашней секции нужные индексы: day - 1 (долгая операция)
4. Выполнить агрегации по вчерашней секции: day - 1 (долгая операция)
5. Удалить старые отсоединенные секции, например позавчерашние (day - 1 - period), в зависимости кол-ва дней, хранимых на диске (по умолчанию 1)
